# -*- coding: utf-8 -*-
"""ASITA_DWM_PRACTICAL_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10AMq3rAGDlMwfRP4w2BNIJD9W1TxeX9e
"""

import pandas as pd
import numpy as np
#data visualization
import matplotlib.pyplot as plt
import seaborn as sns
#machine learning
from sklearn.svm import SVC, LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

data = pd.read_csv('/Placement.csv')

from google.colab import drive
drive.mount('/content/drive')

data

data.head() #gives first five rows of dataset

print('='*50)
print("Describe data")
print('='*50)
print(data.describe())

#As it si clear that we don't need sl_no in training model or in EDA.

data=data.drop(['sl_no'],axis=1)

sns.countplot(data=data,x=data['status'])

data['gender'].value_counts()

df = pd.DataFrame(data.groupby(['gender','status'])['status'].count())
df

sns.countplot(x='gender', hue='status', data=data)

#Conclusion: Male have high chances of getting placed compared to females.

#ssc Percentage

sns.distplot(data['ssc_p'])
plt.title('Distribution of ssc Percentage')
plt.xlabel('ssc %')

sns.catplot(y='ssc_p', x='status', data=data)
plt.xlabel('Employment Status')
plt.ylabel('ssc %')

data['ssc_b'].value_counts()

df = pd.DataFrame(data.groupby(['ssc_b','status'])['status'].count())
df

sns.countplot(x='ssc_b', hue='status', data=data)

#conclusion: From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates. So I am not going to use this feature while training model.

#HSC Percentage

sns.distplot(data['hsc_p'], kde=False)
plt.title('Distribution of HSC Percentage')
plt.xlabel('HSC %')

sns.catplot(y='hsc_p', x='status', data=data)
plt.xlabel('Employment Status')
plt.ylabel('HSC %')

#Conclusion: HSC percentage are important features. As all placed students have higher percentages.

#EDA for HSC Board

data['hsc_b'].value_counts()

df = pd.DataFrame(data.groupby(['hsc_b','status'])['status'].count())
df

sns.countplot(x='hsc_b', hue='status', data=data)

#Conclusion: From the above analysis I can say that, hSC board is not important to recruiters when it come to hiring candidates. So I am not going to use this feature while training model.

#EDA for HSC Specialisation

data['hsc_s'].value_counts()

df = pd.DataFrame(data.groupby(['hsc_s','status'])['status'].count())
df

sns.countplot(x='hsc_s', hue='status', data=data)

#Degree Percentage

sns.distplot(data['degree_p'], kde=False)
plt.title('Distribution of Degree Percentage')
plt.xlabel('Degree %')

sns.catplot(y='degree_p', x='status', data=data)
plt.xlabel('Employment Status')
plt.ylabel('Degree %')

#conclusion: Like SSC and HSC percentages, Degree Percentages are also impotant factor to get placed.

#Work Experience

data['workex'].value_counts()

df = pd.DataFrame(data.groupby(['workex','status'])['status'].count())
df

sns.countplot(x='workex', hue='status', data=data)

##Conclusion: It is clear that candidate with work experience have higher chance of getting placed.

## . Employment Test Percentage"

sns.distplot(data['etest_p'], kde=False)
plt.title('Distribution of MBA Percentage')
plt.xlabel('Employment Test %')

sns.catplot(y='etest_p', x='status', data=data)
plt.xlabel('Employment Status')
plt.ylabel('Employment Test %')

## Corelation between Features

sns.pairplot(data=data[['ssc_p','hsc_p','degree_p', 'etest_p','mba_p','salary', 'status']], hue="status", diag_kind='hist')

#Feature mapping

#Let's drop all unwanted columns as menstioned in above section.

SSC Board
HSC Board
HSC Specialisation
Degree Type
Salary

data.drop(['ssc_b','hsc_b', 'hsc_s', 'degree_t', 'salary'], axis=1, inplace=True)

Let's map categorical feature to numeric one. Categorical features:

Gender : Gender feature have male and female values. I am going to map 0 for male and 1 for female.
Work Experience : Work Experience feature have Yes and No values. I am going to map 0 for No and 1 for Yes.
Status : Status feature have Not Placed and Placed values. Again for this features I am mapping 0 for not placed and 1 for placed values.
Specialisation : Specialisation feature have two values Mkt&HR and Mkt&Fin. I am going to map 0 to Mkt&HR and 1 to Mkt&Fin.

data["gender"] = data.gender.map({"M":0,"F":1})
data["workex"] = data.workex.map({"No":0, "Yes":1})
data["status"] = data.status.map({"Not Placed":0, "Placed":1})
data["specialisation"] = data.specialisation.map({"Mkt&HR":0, "Mkt&Fin":1})

data.columns

data.head()